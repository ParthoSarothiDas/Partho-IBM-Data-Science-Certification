{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89fc7d72-0e56-432d-a7fc-5aeaed63d2a4",
   "metadata": {},
   "source": [
    "# üìú IBM Data Science Professional Certificate  \n",
    "*Curiosity to Capability ‚Äî One Notebook at a Time*\n",
    "\n",
    "---\n",
    "\n",
    "**Compiled and Authored by:**  \n",
    "**Partho Sarothi Das**  \n",
    "Dhaka, Bangladesh  \n",
    "üéì Bachelor's & Master's in Statistics  \n",
    "üíº Investment Banking Professional ‚Üí Aspiring Data Scientist  \n",
    "\n",
    ">**Disclaimer:** This notebook is based on content from the [IBM Data Science Professional Certificate](https://www.coursera.org/professional-certificates/ibm-data-science) offered on Coursera. It is intended for personal learning and review purposes.\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f3b1a7-b928-4d00-87bc-fb27188f198a",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e565cf70-abc0-404c-a38e-c7a1dcb940f7",
   "metadata": {},
   "source": [
    "### Objective\n",
    "\n",
    "Understand the **Data Understanding** stage of the data science methodology, which focuses on exploring and evaluating collected data to ensure it is suitable and representative of the problem.\n",
    "\n",
    "---\n",
    "\n",
    "###  What is Data Understanding?\n",
    "\n",
    "* This stage answers:\n",
    "  üîç *\"Is the data collected truly representative of the problem we're trying to solve?\"*\n",
    "* It involves deep exploration, statistical analysis, and data quality assessment.\n",
    "\n",
    "---\n",
    "\n",
    "### Key Techniques Used\n",
    "\n",
    "1. **Descriptive Statistics** (Univariates):\n",
    "\n",
    "   * Mean, Median, Min, Max, Standard Deviation\n",
    "   * Help summarize the characteristics of each variable\n",
    "\n",
    "2. **Pairwise Correlation**:\n",
    "\n",
    "   * Identify variables that are highly correlated (redundant)\n",
    "   * Helps decide which variables to drop for modeling\n",
    "\n",
    "3. **Histograms**:\n",
    "\n",
    "   * Visual tool to understand variable distributions\n",
    "   * Helps spot skewness, outliers, and opportunities to simplify categorical variables\n",
    "\n",
    "4. **Assessing Data Quality**:\n",
    "\n",
    "   * Identify **missing values**, **invalid entries**, or **anomalies**\n",
    "   * For example:\n",
    "\n",
    "     * Age variable with values 0‚Äì100 and ‚Äú999‚Äù where 999 = \"missing\"\n",
    "     * Recode or remove misleading data\n",
    "\n",
    "---\n",
    "\n",
    "### Case Study Application: Congestive Heart Failure\n",
    "\n",
    "* Initially defined by **primary diagnosis** of heart failure.\n",
    "* During analysis, it was discovered this missed many true cases.\n",
    "* Result: Analysts **looped back to the Data Collection stage** to include **secondary and tertiary diagnoses**.\n",
    "* Shows the **iterative nature** of the methodology: insights at one stage may lead to revisiting earlier stages.\n",
    "\n",
    "---\n",
    "\n",
    "### Why This Matters\n",
    "\n",
    "* Refinement during Data Understanding helps:\n",
    "\n",
    "  * Improve variable selection\n",
    "  * Detect errors and inconsistencies early\n",
    "  * Build a more accurate, representative model\n",
    "  * Prevent misleading or biased outcomes\n",
    "\n",
    "---\n",
    "\n",
    "### Main Takeaways\n",
    "\n",
    "* **Data Understanding** is critical before moving to modeling.\n",
    "* Apply statistics and visualizations to assess quality and relevance.\n",
    "* Be ready to revise your data sources or definitions.\n",
    "* The process is **iterative and interactive** ‚Äî constant refinement leads to better solutions.\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093eecc4-aa9e-4804-bf9e-4458376f75bb",
   "metadata": {},
   "source": [
    "# Data Preparation (Concepts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3af1854-b826-428f-adaf-86b14eb3dc43",
   "metadata": {},
   "source": [
    "### **Objective**\n",
    "\n",
    "To understand the **importance, tasks, and techniques** involved in the **Data Preparation** stage of the data science methodology.\n",
    "\n",
    "---\n",
    "\n",
    "### **What is Data Preparation?**\n",
    "\n",
    "* Like **washing and chopping vegetables**, it involves **cleaning and transforming raw data** into a usable format.\n",
    "* Answers the key question:\n",
    "  üîç *‚ÄúWhat are the ways in which data is prepared?‚Äù*\n",
    "\n",
    "---\n",
    "\n",
    "### **Time Commitment**\n",
    "\n",
    "* Most **time-consuming phase** of a data science project:\n",
    "\n",
    "  * Takes **70‚Äì90%** of total time.\n",
    "  * Can be reduced to **\\~50%** if processes are automated (e.g., via database scripts).\n",
    "  * Saves time for **modeling and analysis**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Activities in Data Preparation**\n",
    "\n",
    "1. **Cleaning the Data**:\n",
    "\n",
    "   * Remove duplicates\n",
    "   * Handle missing or invalid values\n",
    "   * Format data consistently\n",
    "\n",
    "2. **Transforming the Data**:\n",
    "\n",
    "   * Modify raw data into more usable forms\n",
    "   * Make it easier for models to analyze effectively\n",
    "\n",
    "3. **Feature Engineering**:\n",
    "\n",
    "   * Create new features (variables) using domain knowledge\n",
    "   * Enhances predictive power of machine learning models\n",
    "   * Features = characteristics useful in solving the problem\n",
    "\n",
    "4. **Text Analysis (if working with text data)**:\n",
    "\n",
    "   * Encode and process text for modeling\n",
    "   * Ensure groupings are logical and hidden insights are captured\n",
    "\n",
    "---\n",
    "\n",
    "### **Analogy to Cooking**\n",
    "\n",
    "* Just as chopped onions release flavor better than whole ones in sauce,\n",
    "* **Transformed data** enables better insights and modeling results.\n",
    "\n",
    "---\n",
    "\n",
    "### **Why This Stage Is Critical**\n",
    "\n",
    "* Done properly, it sets the foundation for accurate models.\n",
    "* If **skipped or done poorly**, the **entire project can fail** or require major rework.\n",
    "* Attention to detail is **essential**‚Äîeven one ‚Äúbad ingredient‚Äù can spoil the outcome.\n",
    "\n",
    "---\n",
    "\n",
    "### **Main Takeaways**\n",
    "\n",
    "* Data preparation is a **foundational step**.\n",
    "* Involves **cleaning**, **formatting**, **feature engineering**, and **text processing**.\n",
    "* Investing time here results in **better models** and **more reliable outcomes**.\n",
    "* Automating parts of the process can improve efficiency and accuracy.\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaca8f78-39bf-4fbb-90cc-629422ddbcad",
   "metadata": {},
   "source": [
    "# Data Preparation ‚Äì Case Study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe55006-4595-4cbd-9847-4cc132a8a160",
   "metadata": {},
   "source": [
    "### Objective\n",
    "\n",
    "To understand how **data preparation concepts** are practically applied in a real-world **case study on congestive heart failure (CHF)** readmissions.\n",
    "\n",
    "---\n",
    "\n",
    "### Key Analogy\n",
    "\n",
    "Like washing and cleaning vegetables before cooking, **data preparation** involves removing noise, inconsistencies, and restructuring data into a usable form.\n",
    "\n",
    "---\n",
    "\n",
    "### Case Study: CHF Readmission Risk Modeling\n",
    "\n",
    "#### 1. Defining the Problem Clearly\n",
    "\n",
    "* The **first step** was to **define ‚Äúcongestive heart failure (CHF)‚Äù** precisely.\n",
    "\n",
    "  * Required identifying the correct **diagnosis-related group (DRG) codes**.\n",
    "  * CHF is a specific **subset of heart failure**; **clinical input** was essential to get the codes right.\n",
    "\n",
    "#### 2. Readmission Criteria\n",
    "\n",
    "* Defined **readmission** as any return within **30 days** after a discharge related to CHF.\n",
    "\n",
    "  * Based on **clinical guidelines**, 30 days was chosen as the relevant window.\n",
    "  * Differentiated **index admissions** (initial events) from **readmissions**.\n",
    "\n",
    "#### 3. Handling Transactional Data\n",
    "\n",
    "* Patients had **hundreds or thousands** of clinical records:\n",
    "\n",
    "  * Claims from physicians, labs, hospitals\n",
    "  * Diagnoses, prescriptions, procedures\n",
    "* These were **aggregated** to create **a single record per patient** for modeling (as required for decision trees).\n",
    "\n",
    "#### 4. Feature Engineering\n",
    "\n",
    "* Created new variables (columns) during aggregation:\n",
    "\n",
    "  * Visit frequencies\n",
    "  * Recent diagnoses or treatments\n",
    "  * Prescription data\n",
    "  * Co-morbidities (e.g., diabetes, hypertension)\n",
    "\n",
    "#### 5. Literature Review\n",
    "\n",
    "* A **literature review** was conducted to identify **any overlooked variables** or co-morbidities.\n",
    "\n",
    "  * This led to **looping back** to the data collection phase to add missing indicators.\n",
    "\n",
    "#### 6. Merging and Final Dataset\n",
    "\n",
    "* Combined all features with **demographic data** (age, gender, insurance type, etc.).\n",
    "* Resulted in a **single table** where each row represented a patient and each column an attribute.\n",
    "\n",
    "---\n",
    "\n",
    "### Modeling Inputs\n",
    "\n",
    "* **Dependent (target) variable**:\n",
    "\n",
    "  * Readmission within 30 days (Yes/No)\n",
    "* **Cohort size**: 2,343 patients meeting all criteria\n",
    "* Dataset was **split into training and test sets** for modeling and validation.\n",
    "\n",
    "---\n",
    "\n",
    "### Takeaways\n",
    "\n",
    "* Data preparation required:\n",
    "\n",
    "  * **Precise definitions** of medical conditions\n",
    "  * **Aggregation** of transactional records\n",
    "  * **Creation of new features**\n",
    "  * **Clinical and literature insights**\n",
    "* Prepared data laid the foundation for **effective predictive modeling** using a decision tree.\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130a4f2b-c52f-40bb-aaad-a1022fdb8e73",
   "metadata": {},
   "source": [
    "# From Modeling to Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0449eaec-3e80-4918-9bda-f0b2aeca70cb",
   "metadata": {},
   "source": [
    "## Modeling ‚Äì Concepts\n",
    "\n",
    "---\n",
    "\n",
    "### Objective\n",
    "\n",
    "To understand the **purpose** and **characteristics** of the **modeling** stage in the data science methodology.\n",
    "\n",
    "---\n",
    "\n",
    "### Cooking Analogy\n",
    "\n",
    "Modeling is like **tasting the sauce**‚Äîyou check whether your preparation is on track or needs tweaking.\n",
    "\n",
    "---\n",
    "\n",
    "### What is Data Modeling?\n",
    "\n",
    "* **Modeling** is the stage where data scientists develop models to:\n",
    "\n",
    "  * **Describe** patterns or behavior\n",
    "  * **Predict** outcomes (e.g., Yes/No, Stop/Go)\n",
    "\n",
    "* Models are based on the **chosen analytic approach**, which may be:\n",
    "\n",
    "  * Statistical\n",
    "  * Machine Learning\n",
    "\n",
    "* The **training set** (historical data with known outcomes) is used to build and calibrate the model.\n",
    "\n",
    "---\n",
    "\n",
    "### Characteristics of the Modeling Process\n",
    "\n",
    "* Involves **testing various algorithms** to find the best model fit.\n",
    "* Requires checking whether **variables** used are relevant and effective.\n",
    "* Relies heavily on:\n",
    "\n",
    "  * Clear understanding of the problem\n",
    "  * Correct analytic method\n",
    "  * Quality data preparation\n",
    "\n",
    "---\n",
    "\n",
    "### Modeling in the Methodology Framework (John Rollins)\n",
    "\n",
    "Rollins‚Äô framework emphasizes:\n",
    "\n",
    "1. Understanding the business question\n",
    "2. Choosing the right analytic method\n",
    "3. Collecting, understanding, preparing, and modeling the data\n",
    "\n",
    "Modeling is not isolated ‚Äî it's a **dynamic** and **iterative** process involving:\n",
    "\n",
    "* Refinement\n",
    "* Adjustment\n",
    "* Continuous learning\n",
    "\n",
    "---\n",
    "\n",
    "### Outcome\n",
    "\n",
    "* A successful model **answers the business question** effectively.\n",
    "* Evaluation, deployment, and feedback (next stages) ensure the solution is **relevant and useful** in real-world applications.\n",
    "\n",
    "---\n",
    "\n",
    "### Key Takeaway\n",
    "\n",
    "Modeling is where everything comes together ‚Äî **data, preparation, and strategy** ‚Äî to deliver a working solution. It's a critical turning point in the data science lifecycle.\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11db2313-67c0-4682-81a3-e852db8cd6d0",
   "metadata": {},
   "source": [
    "# Modeling ‚Äì Case Study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d0a623-a6a3-437c-85af-fb8260505478",
   "metadata": {},
   "source": [
    "### Objective\n",
    "\n",
    "To demonstrate how **model building**‚Äîspecifically **parameter tuning**‚Äîis applied in a real-world case study on **congestive heart failure readmission**.\n",
    "\n",
    "---\n",
    "\n",
    "### üè• **Case Study Overview**\n",
    "\n",
    "* The goal: **Predict high-risk patients** likely to be readmitted for congestive heart failure.\n",
    "* Method: **Decision tree classification model** using a prepared training dataset.\n",
    "* Focus: Improving model performance‚Äîespecially for predicting **\"yes\" (readmission)** outcomes.\n",
    "\n",
    "---\n",
    "\n",
    "### üîÅ **Model Iteration and Parameter Tuning**\n",
    "\n",
    "#### üîπ **Model 1** (Default setting):\n",
    "\n",
    "* **Overall Accuracy**: 85%\n",
    "* **Accuracy for ‚ÄúYes‚Äù outcomes**: 45%\n",
    "* ‚ùó Too many **false negatives** ‚Üí patients at risk not identified.\n",
    "\n",
    "#### üîπ **Model 2** (Relative cost of misclassifying ‚ÄúYes‚Äù vs. ‚ÄúNo‚Äù set to **9:1**):\n",
    "\n",
    "* **Accuracy for ‚ÄúYes‚Äù**: 97%\n",
    "* **Overall Accuracy**: 49%\n",
    "* ‚ùó Too many **false positives** ‚Üí unnecessary costly interventions.\n",
    "\n",
    "#### üîπ **Model 3** (Relative cost adjusted to **4:1**):\n",
    "\n",
    "* **Sensitivity (Yes)**: 68%\n",
    "* **Specificity (No)**: 85%\n",
    "* **Overall Accuracy**: 81%\n",
    "* ‚úÖ **Best balance** between detecting high-risk patients and avoiding unnecessary actions.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öñÔ∏è **Types of Errors Considered**\n",
    "\n",
    "* **False Positive (Type I Error)**: Predicting a readmission when it won‚Äôt happen ‚Üí waste of resources.\n",
    "* **False Negative (Type II Error)**: Missing a true readmission risk ‚Üí potential harm to the patient and high cost.\n",
    "\n",
    "---\n",
    "\n",
    "### üîÑ **Iterative Nature of Modeling**\n",
    "\n",
    "* Tuning parameters is just one part.\n",
    "* Data scientists often loop back to **data preparation** to refine variables and improve model performance.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ **Key Takeaway**\n",
    "\n",
    "Effective model building in data science involves:\n",
    "\n",
    "* Balancing sensitivity and specificity\n",
    "* Adjusting misclassification costs\n",
    "* Iterating across stages (especially between modeling and data preparation)\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8539fad1-b8a6-45e9-9111-3e07975eeee2",
   "metadata": {},
   "source": [
    "# Data Science Methodology 101: Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327c908c-5f7f-410f-a0d3-031ca1a582dd",
   "metadata": {},
   "source": [
    "### üéØ **Objective**\n",
    "\n",
    "To understand the role of **model evaluation** in the data science methodology and apply it to the congestive heart failure case study.\n",
    "\n",
    "---\n",
    "\n",
    "### üß† **What is Model Evaluation?**\n",
    "\n",
    "* An **iterative process** performed alongside modeling.\n",
    "* Helps assess:\n",
    "\n",
    "  * ‚úÖ Model **quality** (how well it works)\n",
    "  * ‚ùì Whether it answers the **original business question**\n",
    "* Can lead to **model adjustments** if necessary before deployment.\n",
    "\n",
    "---\n",
    "\n",
    "### üîç **Two Main Phases of Evaluation**\n",
    "\n",
    "1. **Diagnostic Measures**\n",
    "\n",
    "   * Checks how the model is functioning.\n",
    "   * For **predictive models**: use tools like **decision trees**.\n",
    "   * For **descriptive models**: compare with **test data** that has known outcomes.\n",
    "\n",
    "2. **Statistical Significance Testing**\n",
    "\n",
    "   * Ensures results are **not due to chance**.\n",
    "   * Confirms that **data has been interpreted correctly**.\n",
    "\n",
    "---\n",
    "\n",
    "### üè• **Case Study Application: Congestive Heart Failure Model**\n",
    "\n",
    "* **Goal**: Select the best model for predicting patient readmissions.\n",
    "* Four models were tested using different **relative misclassification costs**.\n",
    "\n",
    "  * Higher costs for misclassifying ‚Äúyes‚Äù (actual readmissions) improved sensitivity.\n",
    "  * But this also increased **false positives**, which could lead to wasted interventions.\n",
    "\n",
    "---\n",
    "\n",
    "### üìà **ROC Curve for Model Selection**\n",
    "\n",
    "* **ROC = Receiver Operating Characteristic** curve.\n",
    "* Plots **True Positive Rate (Sensitivity)** vs. **False Positive Rate**.\n",
    "* Helps **visualize trade-offs** in model performance.\n",
    "* **Optimal model**: the one with the **maximum separation** from the diagonal baseline.\n",
    "* **Model 3** (with a 4:1 cost ratio) was selected as best:\n",
    "\n",
    "  * Balanced sensitivity and specificity.\n",
    "  * Met both **clinical** and **budgetary constraints**.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ **Key Takeaways**\n",
    "\n",
    "* **Model evaluation is crucial** before deployment.\n",
    "* It validates if the model:\n",
    "\n",
    "  * Accurately answers the business question\n",
    "  * Aligns with real-world constraints (e.g., cost, care quality)\n",
    "* Tools like the **ROC curve** are essential for choosing the most appropriate model.\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ad54a0-8e37-41fb-b96b-7e2917b582d1",
   "metadata": {},
   "source": [
    "![Model to Evaluation](images/Model_to_Evaluation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adf1e50-9baa-45a7-a615-b1a195c7f1ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
