{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c044469a-8ede-491d-a4e1-626af3735e00",
   "metadata": {},
   "source": [
    "# ðŸ“œ IBM Data Science Professional Certificate  \n",
    "*Curiosity to Capability â€” One Notebook at a Time*\n",
    "\n",
    "---\n",
    "\n",
    "**Compiled and Authored by:**  \n",
    "**Partho Sarothi Das**  \n",
    "Dhaka, Bangladesh  \n",
    "ðŸŽ“ Bachelor's & Master's in Statistics  \n",
    "ðŸ’¼ Investment Banking Professional â†’ Aspiring Data Scientist  \n",
    "\n",
    ">**Disclaimer:** This notebook is based on content from the [IBM Data Science Professional Certificate](https://www.coursera.org/professional-certificates/ibm-data-science) offered on Coursera. It is intended for personal learning and review purposes.\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc619ff-675c-4d7e-b9e3-b620b54c013a",
   "metadata": {},
   "source": [
    "# Tools for Data Science â€“ Course Summary\n",
    "\n",
    "This beginner-friendly course introduces a wide range of essential tools that data scientists use to work with and analyze data. It's suitable for learners with or without programming experience and is structured into seven comprehensive modules:\n",
    "\n",
    "#### Module Breakdown:\n",
    "- **Module 1: Overview of Data Science Tools**\n",
    "  - Categories of tools (open source & commercial)\n",
    "  - Functional overlaps, strengths, and limitations\n",
    "\n",
    "- **Module 2: Languages of Data Science**\n",
    "  - Key languages: Python, R, Scala, Java, Julia, SQL\n",
    "  - Use cases and relevance in data workflows\n",
    "\n",
    "- **Module 3: Libraries, APIs, Datasets & Models**\n",
    "  - Built-in libraries for specific functions\n",
    "  - APIs for software interaction\n",
    "  - Data Asset eXchange (DAX) datasets\n",
    "  - Machine learning models and pattern detection\n",
    "\n",
    "- **Module 4: Jupyter Project**\n",
    "  - Jupyter Notebook, JupyterLab, and JupyterLite\n",
    "  - Tools like IBM Watson Studio and Google Colab\n",
    "  - Installation options like Anaconda\n",
    "\n",
    "- **Module 5: RStudio & GitHub**\n",
    "  - Visualizations in R using various packages\n",
    "  - GitHub for project sharing and version control\n",
    "\n",
    "- **Module 6: Final Project**\n",
    "  - Create, share, and peer-review a Jupyter Notebook\n",
    "\n",
    "- **Module 7 (Optional): IBM Tools for Data Science**\n",
    "  - IBM Watson Studio, Cloud Pak, Machine Learning services"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a22c441-0552-4b46-aaaf-df17099d5edd",
   "metadata": {},
   "source": [
    "# Data Science Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8210129-084e-48c6-94b1-ee4ff7c055b6",
   "metadata": {},
   "source": [
    "## Categories of Data Science Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98af3472-665d-4c07-9565-7aa858d30e06",
   "metadata": {},
   "source": [
    "### ðŸ”¹ Data Science Task Categories\n",
    "\n",
    "1. **Data Management**\n",
    "\n",
    "   * Collect, store, and retrieve data securely and efficiently\n",
    "   * Sources: social media, sensors, e-commerce platforms, etc.\n",
    "\n",
    "2. **Data Integration and Transformation (ETL)**\n",
    "\n",
    "   * Extract data from multiple repositories\n",
    "   * Transform data format, structure, and values (e.g., unit conversion)\n",
    "   * Load transformed data into data warehouses\n",
    "\n",
    "3. **Data Visualization**\n",
    "\n",
    "   * Represent data using charts, plots, maps, etc. for better decision-making\n",
    "   * Examples: bar chart, treemap, line chart, map chart\n",
    "\n",
    "4. **Model Building**\n",
    "\n",
    "   * Train machine learning models to identify patterns and make predictions\n",
    "   * Tools: IBM Watson Machine Learning\n",
    "\n",
    "5. **Model Deployment**\n",
    "\n",
    "   * Integrate models into production via APIs\n",
    "   * Allow business applications to access predictions\n",
    "   * Tool: SPSS Collaboration and Deployment Services\n",
    "\n",
    "6. **Model Monitoring and Assessment**\n",
    "\n",
    "   * Ensure ongoing model performance, fairness, and accuracy\n",
    "   * Tools: Fiddler, IBM Watson OpenScale\n",
    "   * Metrics: F1 score, true positive rate, sum of squared error\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”¹ Supporting Tools and Environments\n",
    "\n",
    "1. **Code Asset Management**\n",
    "\n",
    "   * Manages and versions source code\n",
    "   * Supports team collaboration via centralized platforms\n",
    "   * Example: GitHub\n",
    "\n",
    "2. **Data Asset Management (DAM)**\n",
    "\n",
    "   * Organizes and secures data from various sources\n",
    "   * Supports versioning, replication, and access control\n",
    "   * Enables collaborative data handling\n",
    "\n",
    "3. **Development Environments (IDEs)**\n",
    "\n",
    "   * Tools for writing, testing, and deploying code\n",
    "   * Simulate real-world conditions before deployment\n",
    "   * Example: IBM Watson Studio\n",
    "\n",
    "4. **Execution Environments**\n",
    "\n",
    "   * Provide system resources and libraries to run code\n",
    "   * Cloud-based environments offer flexibility and scalability\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary**\n",
    "\n",
    "Data Science involves a series of tasks â€” from data collection to model deployment and monitoring â€” supported by robust tools like DAM, version control, IDEs, and cloud platforms. IBM Watson Studio and IBM Cognos Dashboard are examples of fully integrated platforms covering the full data science lifecycle.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e801a23-9a12-48c5-b3d6-3e8ca7f71533",
   "metadata": {},
   "source": [
    "## **Open-Source Tools for Data Science Part 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d6b3c3-8fbf-42dc-a019-9b51b1bbc42b",
   "metadata": {},
   "source": [
    "**summary** of the **â€œOpen-Source Tools for Data Science Part 1â€**:\n",
    "\n",
    "### 1. Data Management Tools\n",
    "\n",
    "* **Relational Databases**: MySQL, PostgreSQL\n",
    "* **NoSQL Databases**: MongoDB, Apache CouchDB, Apache Cassandra\n",
    "* **File Systems**: Hadoop File System, Ceph (cloud file system)\n",
    "* **Search Engine**: Elasticsearch (text data & indexing)\n",
    "\n",
    "\n",
    "### 2. Data Integration & Transformation Tools\n",
    "\n",
    "* **Apache AirFlow** â€“ workflow orchestration\n",
    "* **KubeFlow** â€“ pipelines on Kubernetes\n",
    "* **Apache Kafka** â€“ real-time data streaming\n",
    "* **Apache Nifi** â€“ visual editor for data flows\n",
    "* **Apache SparkSQL** â€“ scalable SQL processing\n",
    "* **NodeRED** â€“ lightweight, visual data integration (runs on Raspberry Pi)\n",
    "\n",
    "\n",
    "### 3. Data Visualization Tools\n",
    "\n",
    "* **PixieDust** â€“ Python plotting library with UI\n",
    "* **Hue** â€“ SQL-based visualization tool\n",
    "* **Kibana** â€“ works with Elasticsearch\n",
    "* **Apache Superset** â€“ web app for data exploration & visualization\n",
    "\n",
    "### 4. Model Deployment Tools\n",
    "\n",
    "* **Apache PredictionIO** â€“ for SparkML models\n",
    "* **Seldon** â€“ supports many ML frameworks (TensorFlow, R, SparkML, etc.)\n",
    "* **MLeap** â€“ deploy SparkML pipelines\n",
    "* **TensorFlow Serving**, **TensorFlow Lite**, **TensorFlow\\.js** â€“ deploy on server, mobile, or web\n",
    "\n",
    "### 5. Model Monitoring & Assessment Tools\n",
    "\n",
    "* **ModelDB** â€“ metadata repository for models (supports SparkML & scikit-learn)\n",
    "* **Prometheus** â€“ generic monitoring (used for model performance too)\n",
    "* **IBM AI Fairness 360** â€“ detect & mitigate model bias\n",
    "* **IBM Adversarial Robustness 360** â€“ protect models from adversarial attacks\n",
    "* **IBM AI Explainability 360** â€“ explain model decisions\n",
    "\n",
    "\n",
    "### 6. Code Asset Management Tools\n",
    "\n",
    "* **Git** â€“ industry standard version control\n",
    "* **GitHub** â€“ most popular Git service\n",
    "* **GitLab** â€“ open-source & self-hostable\n",
    "* **Bitbucket** â€“ another Git platform\n",
    "\n",
    "### 7. Data Asset Management Tools\n",
    "\n",
    "* **Apache Atlas** â€“ metadata & data governance\n",
    "* **ODPi Egeria** â€“ open metadata sharing across systems\n",
    "* **Kylo** â€“ open-source platform for data asset management\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c28efdd-0eed-42a5-a1f4-0dd1c100e2e9",
   "metadata": {},
   "source": [
    "## **Open-Source Tools for Data Science Part 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8511ab0-4739-4986-8bc3-5c0ffdaac2cd",
   "metadata": {},
   "source": [
    "### 1. Development Environments\n",
    "\n",
    "* **Jupyter Notebooks**\n",
    "\n",
    "  * Supports 100+ languages via \"kernels\"\n",
    "  * Integrates code, documentation, output, visualizations, and shell commands\n",
    "* **JupyterLab**\n",
    "\n",
    "  * More modular and modern\n",
    "  * Allows multi-file layout (notebooks, terminals, datasets) on a flexible canvas\n",
    "* **Apache Zeppelin**\n",
    "\n",
    "  * Jupyter-inspired with **built-in plotting** (no coding required)\n",
    "  * Extensible with libraries\n",
    "* **RStudio**\n",
    "\n",
    "  * Long-established environment for R\n",
    "  * Includes tools for execution, debugging, visualization, and remote data access\n",
    "  * Integrates with Jupyter\n",
    "* **Spyder**\n",
    "\n",
    "  * Python IDE modeled after RStudio\n",
    "  * Not as feature-rich as RStudio but integrates code, plots, and documentation\n",
    "\n",
    "### 2. Cluster Execution Environments\n",
    "\n",
    "* **Apache Spark**\n",
    "\n",
    "  * Most popular for **batch processing**\n",
    "  * Highly scalable; performance increases with more servers\n",
    "* **Apache Flink**\n",
    "\n",
    "  * Focuses on **real-time stream processing**\n",
    "  * Competes with Spark, though Spark is more widely adopted\n",
    "* **Ray**\n",
    "\n",
    "  * Newer tool focused on **large-scale deep learning** model training\n",
    "\n",
    "### 3. Visual & No-Code Tools\n",
    "\n",
    "* **KNIME**\n",
    "\n",
    "  * Drag-and-drop interface\n",
    "  * Built-in visualization & support for R, Python, Apache Spark\n",
    "  * Good for users with minimal coding experience\n",
    "* **Orange**\n",
    "\n",
    "  * Easier to use than KNIME\n",
    "  * Less flexible but beginner-friendly for model building and visualization\n",
    "\n",
    "### Final Takeaway\n",
    "\n",
    "This video introduced key open-source tools across:\n",
    "\n",
    "* **Interactive environments** (e.g., Jupyter, RStudio, Spyder)\n",
    "* **Big data processing platforms** (e.g., Spark, Flink, Ray)\n",
    "* **No-code visual tools** (e.g., KNIME, Orange)\n",
    "\n",
    "These tools support essential tasks like data integration, visualization, model building, and large-scale executionâ€”offering options for both coders and non-programmers in data science."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf4ec4b-b21b-4731-bdfb-57dfbd9919a9",
   "metadata": {},
   "source": [
    "## **Commercial Tools for Data Science**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fa71d7-60b7-420c-8c81-85f715c8f3b4",
   "metadata": {},
   "source": [
    "### 1. Commercial Data Management Tools\n",
    "\n",
    "* Oracle Database\n",
    "* Microsoft SQL Server\n",
    "* IBM Db2\n",
    "\n",
    "> These are industry-standard tools supported by major vendors, valued for their reliability, functionality, and strong commercial support.\n",
    "\n",
    "\n",
    "### 2. Commercial Data Integration & Transformation Tools (ETL)\n",
    "\n",
    "* **Leaders**:\n",
    "\n",
    "  * *Informatica PowerCenter*, *IBM InfoSphere DataStage*\n",
    "* **Others**:\n",
    "\n",
    "  * *SAP*, *Oracle*, *SAS*, *Talend*, *Microsoft*\n",
    "* **Watson Studio Desktop**: Includes **Data Refinery** for spreadsheet-style data integration\n",
    "\n",
    "\n",
    "### 3. Commercial Data Visualization Tools\n",
    "\n",
    "* **Business Intelligence (BI) Tools** for reports and dashboards:\n",
    "\n",
    "  * *Tableau*, *Microsoft Power BI*, *IBM Cognos Analytics*\n",
    "* **Watson Studio Desktop**: Provides data-specific visualizations for data scientists (e.g., column relationships)\n",
    "\n",
    "### 4. Model Building Tools\n",
    "\n",
    "* **SPSS Modeler**\n",
    "* **SAS Enterprise Miner**\n",
    "\n",
    "> SPSS Modeler is also integrated into Watson Studio Desktop.\n",
    "\n",
    "### 5. Model Deployment Tools\n",
    "\n",
    "* **SPSS Collaboration and Deployment Services**: Used for deploying SPSS assets\n",
    "* Commercial tools support model export in open formats like **PMML** (Predictive Model Markup Language)\n",
    "\n",
    "### 6. Model Monitoring\n",
    "\n",
    "* **Not widely supported** in commercial tools yet\n",
    "* **Open-source tools** are preferred (e.g., IBM Watson Open Scale for fairness and monitoring)\n",
    "\n",
    "### 7. Code Asset Management\n",
    "\n",
    "* **Git & GitHub** (Open-source standards)\n",
    "\n",
    "> Commercial alternatives are not widely adopted\n",
    "\n",
    "### 8. Data Asset Management (Data Governance & Lineage)\n",
    "\n",
    "* **Informatica Enterprise Data Governance**\n",
    "* **IBM Information Governance Catalog**: Includes features like:\n",
    "\n",
    "  * Data dictionary\n",
    "  * Data steward assignment\n",
    "  * Data lineage tracking\n",
    "  * Policy and rule management for compliance\n",
    "\n",
    "### 9. Development Environments & Integrated Platforms\n",
    "\n",
    "* **Watson Studio (Cloud & Desktop)**:\n",
    "\n",
    "  * Combines Jupyter Notebooks and graphical tools\n",
    "  * Integrated with **Watson Open Scale** for full lifecycle support\n",
    "  * Deployable on-premises, Kubernetes, or RedHat OpenShift\n",
    "* **H2O Driverless AI**:\n",
    "\n",
    "  * Fully automated platform covering the complete data science workflow\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
